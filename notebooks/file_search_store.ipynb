{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b1ec65",
   "metadata": {},
   "source": [
    "# File Search Store Management\n",
    "\n",
    "A notebook to demonstrate how to create and manage a Gemini FileSearchStore.\n",
    "\n",
    "The best way to run this notebook is from Google Colab.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/derailed-dash/gemini-file-search-demo/blob/main/notebooks/file_search_store.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639f75a",
   "metadata": {},
   "source": [
    "## Pre-Reqs and Notes\n",
    "\n",
    "- The `file_search_stores` is a feature exclusive to the Gemini Developer API. \n",
    "  - It does not work with the Vertex AI API or the Gen AI SDK in Vertex AI mode.\n",
    "  - Therefore: don't set env vars for `GOOGLE_CLOUD_LOCATION` or `GOOGLE_GENAI_USE_VERTEXAI` and do not initialise Vertex AI.\n",
    "- Make sure you have an up-to-date version of the `google-genai` package installed. \n",
    "  - Versions older than 1.49.0 do not support the File Search Tool.\n",
    "  - You can upgrade the package using `pip install --upgrade google-genai`.\n",
    "  - You can add to your `pyproject.toml` file; since we don't explicitly need it outside of this notebook, we can add it to the `[jupyter]` section.\n",
    "- Add your Gemini API Key to Colab as a secret. Then you can retrieve it using `userdata.get(\"GEMINI_API_KEY\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68e9c1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97210f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:13.376390Z",
     "iopub.status.busy": "2026-01-07T19:22:13.376265Z",
     "iopub.status.idle": "2026-01-07T19:22:14.724055Z",
     "shell.execute_reply": "2026-01-07T19:22:14.722749Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576bcec",
   "metadata": {},
   "source": [
    "\n",
    "### Local Only\n",
    "\n",
    "If running locally, setup the Google Cloud environment:\n",
    "\n",
    "```bash\n",
    "source scripts/setup-env.sh\n",
    "```\n",
    "\n",
    "Then to install the package dependencies into the virtual environment, use the `uv` tool:\n",
    "\n",
    "1. From your agent's root directory, run `make install` to set up the virtual environment (`.venv`).\n",
    "2. In this Jupyter notebook, select the kernel from the `.venv` folder to ensure all dependencies are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1ade3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:14.726286Z",
     "iopub.status.busy": "2026-01-07T19:22:14.726042Z",
     "iopub.status.idle": "2026-01-07T19:22:14.730528Z",
     "shell.execute_reply": "2026-01-07T19:22:14.729563Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Current CWD: {os.getcwd()}\")\n",
    "\n",
    "# Load env vars\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"Warning: GEMINI_API_KEY environment variable not set. Client may fail.\")\n",
    "else:\n",
    "    print(\"Successfully loaded Gemini API key.\")\n",
    "\n",
    "STORE_NAME = os.getenv(\"STORE_NAME\")\n",
    "if not STORE_NAME:\n",
    "    print(\"Warning: STORE_NAME environment variable not set. You will not be able to work with the store.\")\n",
    "else:\n",
    "    print(f\"Successfully loaded Gemini File Search Store: {STORE_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a6f7f",
   "metadata": {},
   "source": [
    "### Or In Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee8b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:14.731921Z",
     "iopub.status.busy": "2026-01-07T19:22:14.731794Z",
     "iopub.status.idle": "2026-01-07T19:22:14.734020Z",
     "shell.execute_reply": "2026-01-07T19:22:14.733275Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q -U \"google-genai>=1.49.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb10c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:14.735651Z",
     "iopub.status.busy": "2026-01-07T19:22:14.735496Z",
     "iopub.status.idle": "2026-01-07T19:22:14.738210Z",
     "shell.execute_reply": "2026-01-07T19:22:14.737264Z"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a074a3",
   "metadata": {},
   "source": [
    "### Client Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5175e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:14.739945Z",
     "iopub.status.busy": "2026-01-07T19:22:14.739838Z",
     "iopub.status.idle": "2026-01-07T19:22:14.779840Z",
     "shell.execute_reply": "2026-01-07T19:22:14.778943Z"
    }
   },
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42055dd4",
   "metadata": {},
   "source": [
    "## Store Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c9c175",
   "metadata": {},
   "source": [
    "### View All Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec353b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:14.782135Z",
     "iopub.status.busy": "2026-01-07T19:22:14.782021Z",
     "iopub.status.idle": "2026-01-07T19:22:15.122895Z",
     "shell.execute_reply": "2026-01-07T19:22:15.121672Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for a_store in client.file_search_stores.list():\n",
    "        print(a_store)\n",
    "except Exception as e:\n",
    "    print(f\"Error listing stores (check creds?): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f0dfbd",
   "metadata": {},
   "source": [
    "### Retrieve the Store\n",
    "\n",
    "Here's a utility function to retrieve the store(s) that match a given display name. Note that display name is not unique, so this function returns the first matching store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b80190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:15.125286Z",
     "iopub.status.busy": "2026-01-07T19:22:15.125157Z",
     "iopub.status.idle": "2026-01-07T19:22:15.128127Z",
     "shell.execute_reply": "2026-01-07T19:22:15.127283Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_store(store_name: str):\n",
    "    \"\"\"Retrieve a store by display name\"\"\"\n",
    "    try:\n",
    "        for a_store in client.file_search_stores.list():\n",
    "            if a_store.display_name == store_name:\n",
    "                return a_store\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_store path: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d3346a",
   "metadata": {},
   "source": [
    "### Create the Store (One Time)\n",
    "\n",
    "Once you've created the store, save the store ID for use in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954029c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:15.129615Z",
     "iopub.status.busy": "2026-01-07T19:22:15.129514Z",
     "iopub.status.idle": "2026-01-07T19:22:15.366611Z",
     "shell.execute_reply": "2026-01-07T19:22:15.365785Z"
    }
   },
   "outputs": [],
   "source": [
    "if not get_store(STORE_NAME):\n",
    "    file_search_store = client.file_search_stores.create(config={\"display_name\": STORE_NAME})\n",
    "    print(f\"Created store: {file_search_store.name}\")\n",
    "else:\n",
    "    print(f\"Store {STORE_NAME} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe601a",
   "metadata": {},
   "source": [
    "### View the Store\n",
    "\n",
    "We can interrogate a store and see what files have been uploaded to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc694cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:15.368219Z",
     "iopub.status.busy": "2026-01-07T19:22:15.368093Z",
     "iopub.status.idle": "2026-01-07T19:22:15.931639Z",
     "shell.execute_reply": "2026-01-07T19:22:15.930451Z"
    }
   },
   "outputs": [],
   "source": [
    "file_search_store = get_store(STORE_NAME)\n",
    "if not file_search_store:\n",
    "    print(f\"Store {STORE_NAME} not found.\")\n",
    "else:\n",
    "    print(file_search_store)\n",
    "\n",
    "    # List all documents in the store\n",
    "    # The 'parent' argument is the resource name of the store\n",
    "    docs = client.file_search_stores.documents.list(parent=file_search_store.name)\n",
    "    try:\n",
    "        doc_list = list(docs)\n",
    "        print(f\"Docs in {STORE_NAME}: {len(doc_list)}\")\n",
    "\n",
    "        if not doc_list:\n",
    "            print(\"No documents found in the store.\")\n",
    "        else:\n",
    "            for i, doc in enumerate(doc_list):\n",
    "                section_heading = f\"Document {i}:\"\n",
    "                print(\"-\" * len(section_heading))\n",
    "                print(section_heading)\n",
    "                print(\"-\" * len(section_heading))\n",
    "                print(f\"  Display name:{doc.display_name}\")\n",
    "                print(f\"  ID: {doc.name}\")\n",
    "                print(f\"  Metadata: {doc.custom_metadata}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing docs (might be empty): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82077a",
   "metadata": {},
   "source": [
    "### Delete Store(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6987c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:15.933334Z",
     "iopub.status.busy": "2026-01-07T19:22:15.933224Z",
     "iopub.status.idle": "2026-01-07T19:22:16.203761Z",
     "shell.execute_reply": "2026-01-07T19:22:16.202632Z"
    }
   },
   "outputs": [],
   "source": [
    "# First, point to the right store. For example:\n",
    "file_search_store = get_store(STORE_NAME)\n",
    "\n",
    "# Delete the store\n",
    "if file_search_store:\n",
    "    print(f\"Store found: {file_search_store.name}\")\n",
    "    # print(f\"Deleting {file_search_store}\")\n",
    "    # Uncomment to delete\n",
    "    # client.file_search_stores.delete(name=file_search_store.name, config={'force': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11668f60",
   "metadata": {},
   "source": [
    "## Upload and Process Files\n",
    "\n",
    "Now we need to place the files in a suitable local folder to upload to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4e1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:16.205721Z",
     "iopub.status.busy": "2026-01-07T19:22:16.205528Z",
     "iopub.status.idle": "2026-01-07T19:22:16.208430Z",
     "shell.execute_reply": "2026-01-07T19:22:16.207548Z"
    }
   },
   "outputs": [],
   "source": [
    "UPLOAD_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055ca61a",
   "metadata": {},
   "source": [
    "Create some utility classes and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f54dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:16.210184Z",
     "iopub.status.busy": "2026-01-07T19:22:16.210086Z",
     "iopub.status.idle": "2026-01-07T19:22:16.215938Z",
     "shell.execute_reply": "2026-01-07T19:22:16.215340Z"
    }
   },
   "outputs": [],
   "source": [
    "class DocumentMetadata(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    abstract: str\n",
    "\n",
    "\n",
    "def delete_doc(doc, file_search_store):\n",
    "    \"\"\"Delete document(s) from the file search store\"\"\"\n",
    "    print(f\"♻️  Deleting duplicate: '{doc.display_name}' (ID: {doc.name})\")\n",
    "    client.file_search_stores.documents.delete(name=doc.name, config={\"force\": True})\n",
    "    time.sleep(2)  # small throttle and allow propagation\n",
    "\n",
    "\n",
    "def generate_metadata(file_name: str, temp_file) -> DocumentMetadata:\n",
    "    \"\"\"Generate metadata for a document\"\"\"\n",
    "\n",
    "    print(f\"Extracting metadata from {file_name}...\")\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=[\n",
    "            \"\"\"Please extract title, author, and short abstract from this document. \n",
    "            Each value should be under 200 characters.\n",
    "\n",
    "            Abstracts should be succinct and NOT include preamble text like `This document describes...`\n",
    "\n",
    "            Example bad abstract: \n",
    "            Now I want to cover a key consideration that can potentially \n",
    "            save you more in future IT spend than any other decision you can make: \n",
    "            embracing open source as a core element of your cloud strategy.\n",
    "\n",
    "            Example good abstract:\n",
    "            How you can significantly reduce IT spend by embracing open source\n",
    "            as a core component of your cloud strategy.\n",
    "\n",
    "            Example bad abstract:\n",
    "            This article discusses how you can design your cloud landing zone.\n",
    "\n",
    "            Example good abstract:\n",
    "            How to design your cloud landing zone according to best practices.\n",
    "            \"\"\",\n",
    "            temp_file,\n",
    "        ],\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_schema\": DocumentMetadata,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    metadata: DocumentMetadata = response.parsed\n",
    "    print(f\"Title: {metadata.title}\")\n",
    "    print(f\"Author: {metadata.author}\")\n",
    "    print(f\"Abstract: {metadata.abstract}\")\n",
    "\n",
    "    return metadata\n",
    "\n",
    "\n",
    "def upload_doc(file_path, file_search_store):\n",
    "    \"\"\"Upload a document to the file search store\"\"\"\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    print(f\"Uploading {file_name} for metadata extraction...\")\n",
    "    temp_file = client.files.upload(file=file_path)\n",
    "\n",
    "    # Verify file is active (ready for inference)\n",
    "    while temp_file.state.name == \"PROCESSING\":\n",
    "        print(\"Still uploading...\", end=\"\\r\")\n",
    "        time.sleep(2)\n",
    "        temp_file = client.files.get(name=temp_file.name)\n",
    "\n",
    "    if temp_file.state.name != \"ACTIVE\":\n",
    "        raise RuntimeError(f\"File upload failed with state: {temp_file.state.name}\")\n",
    "\n",
    "    # Now let's check if this is a replacement of an existing file\n",
    "    # If so, we should delete the existing entry first\n",
    "    # Iterate through all docs in the store\n",
    "    for doc in client.file_search_stores.documents.list(parent=file_search_store.name):\n",
    "        should_delete = False\n",
    "\n",
    "        # Match by Display Name\n",
    "        if doc.display_name == file_name:\n",
    "            should_delete = True\n",
    "\n",
    "        # Match by Custom Metadata (Robust Match)\n",
    "        # This catches docs where display_name was set to the Title\n",
    "        elif doc.custom_metadata:\n",
    "            for meta in doc.custom_metadata:\n",
    "                if meta.key == \"file_name\" and meta.string_value == file_name:\n",
    "                    should_delete = True\n",
    "                    break\n",
    "\n",
    "        if should_delete:\n",
    "            delete_doc(doc, file_search_store)\n",
    "\n",
    "    metadata = generate_metadata(file_name, temp_file)\n",
    "\n",
    "    # Import the file into the file search store with custom metadata\n",
    "    operation = client.file_search_stores.upload_to_file_search_store(\n",
    "        file_search_store_name=file_search_store.name,\n",
    "        file=file_path,\n",
    "        config={\n",
    "            \"display_name\": metadata.title,\n",
    "            \"custom_metadata\": [\n",
    "                {\"key\": \"title\", \"string_value\": metadata.title},\n",
    "                {\"key\": \"file_name\", \"string_value\": file_name},\n",
    "                {\"key\": \"author\", \"string_value\": metadata.author},\n",
    "                {\"key\": \"abstract\", \"string_value\": metadata.abstract},\n",
    "            ],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Wait until import is complete\n",
    "    while not operation.done:\n",
    "        time.sleep(5)\n",
    "        print(\"Still importing...\")\n",
    "        operation = client.operations.get(operation)\n",
    "\n",
    "    print(f\"{file_name} successfully uploaded and indexed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880dd56",
   "metadata": {},
   "source": [
    "Now actually **upload and process our documents**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddb63221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:16.217773Z",
     "iopub.status.busy": "2026-01-07T19:22:16.217658Z",
     "iopub.status.idle": "2026-01-07T19:22:55.874763Z",
     "shell.execute_reply": "2026-01-07T19:22:55.874052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files to fileSearchStores/demofilestore-rsf3q46u6fcu...\n",
      "Uploading ../data/story.md\n",
      "Uploading story.md for metadata extraction...\n",
      "♻️  Deleting duplicate: 'The Wormhole Incursion' (ID: fileSearchStores/demofilestore-rsf3q46u6fcu/documents/the-wormhole-incursion-o25713mzzb51)\n",
      "Extracting metadata from story.md...\n",
      "Title: The Wormhole Incursion: A Squadron Chronicle\n",
      "Author: Unknown\n",
      "Abstract: Commander Dazbo leads his unique AI-piloted squadron to defend a mining colony from a Krellon wormhole invasion, culminating in the destruction of the alien mothership, the Star-Eater.\n",
      "Still importing...\n",
      "story.md successfully uploaded and indexed\n",
      "Upload complete.\n"
     ]
    }
   ],
   "source": [
    "file_search_store = get_store(STORE_NAME)\n",
    "if file_search_store is None:\n",
    "    print(f\"Store {STORE_NAME} not found.\")\n",
    "else:\n",
    "    print(f\"Uploading files to {file_search_store.name}...\")\n",
    "    files_to_upload = glob.glob(f\"{UPLOAD_PATH}/*\")\n",
    "    if files_to_upload:\n",
    "        for file_path in files_to_upload:\n",
    "            print(f\"Uploading {file_path}\")\n",
    "            upload_doc(file_path, file_search_store)\n",
    "        print(\"Upload complete.\")\n",
    "    else:\n",
    "        print(f\"No files found in {UPLOAD_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_query",
   "metadata": {},
   "source": [
    "## Verify with Query\n",
    "\n",
    "Now that the data is uploaded, let's verify we can retrieve it using the File Search Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "verify_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-07T19:22:55.876828Z",
     "iopub.status.busy": "2026-01-07T19:22:55.876717Z",
     "iopub.status.idle": "2026-01-07T19:22:58.643663Z",
     "shell.execute_reply": "2026-01-07T19:22:58.642759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying store: fileSearchStores/demofilestore-rsf3q46u6fcu (demo-file-store)\n",
      "FileSearch tool config...\n",
      "\n",
      "Response:\n",
      "The 'Too Many Pies' Anaconda has a cargo capacity of 258 tons of munitions.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the store again to be sure\n",
    "store = get_store(STORE_NAME)\n",
    "\n",
    "if store:\n",
    "    print(f\"Querying store: {store.name} ({store.display_name})\")\n",
    "\n",
    "    try:\n",
    "        # Use the File Search Tool\n",
    "        if hasattr(types, \"FileSearch\"):\n",
    "            print(\"FileSearch tool config...\")\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=\"What is the cargo capacity of the 'Too Many Pies' Anaconda?\",\n",
    "                config=types.GenerateContentConfig(\n",
    "                    tools=[types.Tool(file_search=types.FileSearch(file_search_store_names=[store.name]))]\n",
    "                ),\n",
    "            )\n",
    "            print(\"\\nResponse:\")\n",
    "            print(response.text)\n",
    "        else:\n",
    "            print(\"types.FileSearch not found. Skipping in-notebook query verification.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Store not found, cannot verify.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154caaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
